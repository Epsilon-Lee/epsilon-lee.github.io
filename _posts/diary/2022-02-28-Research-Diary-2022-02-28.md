---
layout: post
title: "Research Diary from 2022/02/28"
author: Guanlin Li
tag: diary
---

- toc
{:toc}
### 02/28

#### Tips

```bash
nohup train.sh > log/logfilename &  # run in background with std/err outputs in log file
```



---

#### thesis related

- `IWSLT17 FR-EN` baseline is out, valid best BLEU: **39.6**

- ~~Implement ST, BT, TA training.~~

  - *Walk through* `generate.py` or other files to learn how to decode a file and restore its instance order.

    > - ST is to use the baseline/forward model to generate train target.
    > - BT is to use the backward model to generate train source.
    > - TA is to use the forward right-to-left model to generate train target.
    >   - How to train with right-to-left order? e.g. change the batch format in train_step?

- Run `IWSLT17 EN-FR` baseline (2 A100): valid best BLEU: **40.33**

- Run `WMT20 ZH-EN` baseline (4 A100)

  - dropout 0.15, warmup-step: 4000, lr: 5e-4 $$\Rightarrow$$ valid best BLEU: 15.95
  - dropout 0.25, warmup-step: 4000, lr: 5e-4 $$\Rightarrow$$ valid best BLEU: 16.24 (epoch 30+)

---

#### A bag of questions about details in TOD papers

- In simpleTOD, what is the initialization of the autoregressive decoder-only model? Is that initialization the same as that of SOLOIST?
- Does simpleTOD include dialogue acts in the sequence of autoregressive training tokens? How about SOLOIST?
- Figure out the difference between end-to-end evaluation results and context-to-response evaluation.
  - They both can be evaluated w.r.t. Inform, Success, BLEU, Combined. 

- What is the concept of `session` mean? What are the differences between `session` and dialogue?

- **[IMPORTANT]** How to evaluate without dialogue states? read the `evaluate.py` script [here](https://github.com/budzianowski/multiwoz/blob/master/evaluate.py).

