---
layout: post
title: "Research Diary from 2022/02/28"
author: Guanlin Li
tag: diary
---

- toc
{:toc}

### Tips

```bash
nohup train.sh > log/logfilename &  # run in background with std/err outputs in log file
```



### 02/28

---

#### thesis related

- `IWSLT17 FR-EN` baseline is out, valid best BLEU: **39.6**

- ~~Implement ST, BT, TA training.~~

  - *Walk through* `generate.py` or other files to learn how to decode a file and restore its instance order.

    > - ST is to use the baseline/forward model to generate train target.
    > - BT is to use the backward model to generate train source.
    > - TA is to use the forward right-to-left model to generate train target.
    >   - How to train with right-to-left order? e.g. change the batch format in train_step?

- Run `IWSLT17 EN-FR` baseline (2 A100): valid best BLEU: **40.33**

- Run `WMT20 ZH-EN` baseline (2 A100)

  - dropout 0.15, warmup-step: 4000, lr: 5e-4 $$\Rightarrow$$ valid best BLEU: 15.95
  - dropout 0.25, warmup-step: 4000, lr: 5e-4 $$\Rightarrow$$ valid best BLEU: 16.24 (epoch 30+)

---

#### A bag of questions about details in TOD papers

- In simpleTOD, what is the initialization of the autoregressive decoder-only model? Is that initialization the same as that of SOLOIST?
- Does simpleTOD include dialogue acts in the sequence of autoregressive training tokens? How about SOLOIST?
- Figure out the difference between end-to-end evaluation results and context-to-response evaluation.
  - They both can be evaluated w.r.t. Inform, Success, BLEU, Combined. 

- What is the concept of `session` mean? What are the differences between `session` and dialogue?

- **[IMPORTANT]** How to evaluate without dialogue states? read the `evaluate.py` script [here](https://github.com/budzianowski/multiwoz/blob/master/evaluate.py).



### 03/01

---

#### thesis related

- Training

  - Run `WMT20 EN-ZH` baseline (2 A100), using same hyperparameter as `ZH-EN` direction.
  - Run `WMT14 EN-DE` and `DE-EN` baseline (2 A100), using the old hyperparameters.

- Testing

  - `EN-FR`, `FR-EN`, detokenized (via `SacreBLEU==1.5.1`) BERTScore with respect to reference.
  - Same to `EN-DE` and `ZH-EN`.

  > **[IMPORTANT]** Write scripts to extract Detokenized reference and hypothesis text from output of `generate.py`.

---

#### Answer [A bag of questions about details in TOD papers](#a-bag-of-questions-about-details-in-tod-papers)





#### Walk through evaluation in Multiwoz (DST and E2E Dialogue Generation)

> Re-run simpleTOD/UBAR and Zero-Shot DST.

